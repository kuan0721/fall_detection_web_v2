from flask import Flask, render_template, request, jsonify, Response
from flask_socketio import SocketIO, emit
import cv2
import numpy as np
import mediapipe as mp
import json
import threading
import time
import os
import requests
from datetime import datetime
import base64
from io import BytesIO
from PIL import Image

# å°å…¥æ‚¨çš„è·Œå€’æª¢æ¸¬æ¨¡çµ„
from test03 import (
    Params,
    FallDetector,
    MultiTracker,
    ensure_model,
    open_capture,
    _to_px_normed,
    _valid,
    _center,
    _torso_angle_deg,
    _bbox_from_points,
    estimate_input_fps,
)

app = Flask(__name__)
app.config["SECRET_KEY"] = "your-secret-key-here"
socketio = SocketIO(app, cors_allowed_origins="*")

# Telegram Bot è¨­å®š
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN", "YOUR_BOT_TOKEN_HERE")
TELEGRAM_CHAT_ID = os.getenv("TELEGRAM_CHAT_ID", "YOUR_CHAT_ID_HERE")

# MediaPipe è¨­å®š
from mediapipe.tasks.python import vision as mp_vision
from mediapipe.tasks.python.core.base_options import BaseOptions
from mediapipe.framework.formats import landmark_pb2

mp_pose_enum = mp.solutions.pose.PoseLandmark
mp_draw = mp.solutions.drawing_utils
POSE_CONN = mp.solutions.pose.POSE_CONNECTIONS
LM_SPEC = mp_draw.DrawingSpec(thickness=2, circle_radius=2)
CONN_SPEC = mp_draw.DrawingSpec(thickness=2)


class FallDetectionApp:
    def __init__(self):
        self.is_monitoring = False
        self.cap = None
        self.landmarker = None
        self.tracker = None
        self.params = Params(
            fall_vdrop=0.10,
            fall_angle_deg=55.0,
            fall_aspect=1.00,
            fall_dwell_s=0.3,
            candidate_window_s=1.0,
            min_vis=0.5,
        )
        self.last_notification_time = {}
        self.notification_cooldown = 30  # 30ç§’å…§ä¸é‡è¤‡é€šçŸ¥

    def send_telegram_notification(self, message, image_data=None):
        """ç™¼é€Telegramé€šçŸ¥"""
        try:
            url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
            data = {"chat_id": TELEGRAM_CHAT_ID, "text": message, "parse_mode": "HTML"}

            response = requests.post(url, data=data)

            # å¦‚æœæœ‰åœ–ç‰‡ï¼Œä¹Ÿç™¼é€åœ–ç‰‡
            if image_data is not None:
                photo_url = (
                    f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendPhoto"
                )
                files = {"photo": image_data}
                photo_data = {"chat_id": TELEGRAM_CHAT_ID, "caption": message}
                requests.post(photo_url, data=photo_data, files=files)

            return response.status_code == 200
        except Exception as e:
            print(f"Telegramé€šçŸ¥ç™¼é€å¤±æ•—: {e}")
            return False

    def process_frame(self, frame, ts_s):
        """è™•ç†å–®ä¸€å¹€ä¸¦æª¢æ¸¬è·Œå€’"""
        H, W = frame.shape[:2]

        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb)
        ts_ms = int(ts_s * 1000)
        res = self.landmarker.detect_for_video(mp_image, ts_ms)

        annotated = frame.copy()
        centers = []
        horiz_flags = []
        bboxes = []
        fall_detected = False

        if res and res.pose_landmarks:
            for person_idx, lm_list in enumerate(res.pose_landmarks):
                lms = lm_list
                try:
                    # å–å¾—é—œéµé»
                    l_sh = lms[mp_pose_enum.LEFT_SHOULDER.value]
                    r_sh = lms[mp_pose_enum.RIGHT_SHOULDER.value]
                    l_hp = lms[mp_pose_enum.LEFT_HIP.value]
                    r_hp = lms[mp_pose_enum.RIGHT_HIP.value]
                    nose = lms[mp_pose_enum.NOSE.value]
                    l_ank = lms[mp_pose_enum.LEFT_ANKLE.value]
                    r_ank = lms[mp_pose_enum.RIGHT_ANKLE.value]

                    # è½‰æ›ç‚ºåƒç´ åº§æ¨™
                    l_sh_px = _to_px_normed(l_sh, W, H)
                    r_sh_px = _to_px_normed(r_sh, W, H)
                    l_hp_px = _to_px_normed(l_hp, W, H)
                    r_hp_px = _to_px_normed(r_hp, W, H)
                    nose_px = _to_px_normed(nose, W, H)
                    l_ank_px = _to_px_normed(l_ank, W, H)
                    r_ank_px = _to_px_normed(r_ank, W, H)

                    if all(
                        _valid(p, self.params.min_vis)
                        for p in [l_sh_px, r_sh_px, l_hp_px, r_hp_px]
                    ):
                        shoulder_c = _center(l_sh_px, r_sh_px)
                        hip_c = _center(l_hp_px, r_hp_px)
                        torso_angle = _torso_angle_deg(shoulder_c, hip_c)
                        center_y_px = (shoulder_c[1] + hip_c[1]) / 2.0

                        # è¨ˆç®—bbox
                        lm_xy = [(shoulder_c[0], shoulder_c[1]), (hip_c[0], hip_c[1])]
                        for p in (nose_px, l_ank_px, r_ank_px):
                            if _valid(p, self.params.min_vis):
                                lm_xy.append((p[0], p[1]))

                        if len(lm_xy) >= 2:
                            x1, y1, x2, y2 = _bbox_from_points(lm_xy)
                            w_box = max(1.0, x2 - x1)
                            h_box = max(1.0, y2 - y1)
                            bbox_aspect = w_box / h_box

                            horizontal_ok = (
                                torso_angle >= self.params.fall_angle_deg
                            ) or (bbox_aspect >= self.params.fall_aspect)

                            centers.append(
                                ((shoulder_c[0] + hip_c[0]) / 2.0, center_y_px)
                            )
                            horiz_flags.append(horizontal_ok)
                            bboxes.append((int(x1), int(y1), int(x2), int(y2)))

                    # ç•«éª¨æ¶
                    nl = landmark_pb2.NormalizedLandmarkList(
                        landmark=[
                            landmark_pb2.NormalizedLandmark(
                                x=float(lm.x),
                                y=float(lm.y),
                                z=float(lm.z),
                                visibility=1.0,
                            )
                            for lm in lms
                        ]
                    )
                    mp_draw.draw_landmarks(
                        annotated,
                        nl,
                        POSE_CONN,
                        landmark_drawing_spec=LM_SPEC,
                        connection_drawing_spec=CONN_SPEC,
                    )
                except Exception as e:
                    continue

        # å¤šäººç‹€æ…‹æ›´æ–°
        if centers:
            states, dets = self.tracker.update(ts_s, centers, horiz_flags)
        else:
            self.tracker.update(ts_s, [], [])
            states, dets = [], []

        # è¦–è¦ºåŒ–å’Œé€šçŸ¥
        for i, (state, box) in enumerate(zip(states, bboxes)):
            if not box:
                continue

            x1, y1, x2, y2 = box

            if state == "FALLEN":
                fall_detected = True

                # æª¢æŸ¥é€šçŸ¥å†·å»æ™‚é–“
                now = time.time()
                person_key = f"person_{i}"

                if (
                    person_key not in self.last_notification_time
                    or now - self.last_notification_time[person_key]
                    > self.notification_cooldown
                ):

                    # æº–å‚™é€šçŸ¥è¨Šæ¯
                    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    message = f"ğŸš¨ <b>è·Œå€’è­¦å ±!</b>\n\nâ° æ™‚é–“: {timestamp}\nğŸ‘¤ æª¢æ¸¬åˆ°ç¬¬ {i+1} äººè·Œå€’\nğŸ“ ä½ç½®: ç›£æ§å€åŸŸ"

                    # æº–å‚™åœ–ç‰‡
                    try:
                        _, buffer = cv2.imencode(".jpg", annotated)
                        img_bytes = BytesIO(buffer)

                        # ç™¼é€é€šçŸ¥
                        if self.send_telegram_notification(message, img_bytes):
                            self.last_notification_time[person_key] = now

                            # é€šéWebSocketç™¼é€çµ¦å‰ç«¯
                            socketio.emit(
                                "fall_detected",
                                {
                                    "person_id": i,
                                    "timestamp": timestamp,
                                    "bbox": [x1, y1, x2, y2],
                                },
                            )
                    except Exception as e:
                        print(f"è™•ç†è·Œå€’é€šçŸ¥æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

                # è¦–è¦ºæ¨™è¨˜
                overlay = annotated.copy()
                cv2.rectangle(
                    overlay,
                    (max(0, x1 - 8), max(0, y1 - 8)),
                    (min(W - 1, x2 + 8), min(H - 1, y2 + 8)),
                    (0, 0, 255),
                    -1,
                )
                annotated = cv2.addWeighted(overlay, 0.20, annotated, 0.80, 0)
                cv2.putText(
                    annotated,
                    "FALL DETECTED",
                    (max(5, x1), max(30, y1 - 10)),
                    cv2.FONT_HERSHEY_DUPLEX,
                    0.8,
                    (0, 0, 255),
                    2,
                )

            # ç•«é‚Šæ¡†
            color = (0, 0, 255) if state == "FALLEN" else (0, 255, 0)
            cv2.rectangle(annotated, (x1, y1), (x2, y2), color, 2)

        return annotated, fall_detected, len(centers)

    def start_monitoring(self, source="0", model_name="heavy"):
        """é–‹å§‹ç›£æ§"""
        if self.is_monitoring:
            return False

        try:
            # åˆå§‹åŒ–æ”å½±æ©Ÿ
            self.cap = open_capture(source)
            ok, frame = self.cap.read()
            if not ok:
                raise RuntimeError("ç„¡æ³•è®€å–æ”å½±æ©Ÿ")

            H, W = frame.shape[:2]
            input_fps = estimate_input_fps(self.cap, source)

            # åˆå§‹åŒ–è¿½è¹¤å™¨
            dist_thresh = max(80.0, 0.08 * max(W, H))
            self.tracker = MultiTracker(
                img_h=H, params=self.params, dist_thresh_px=dist_thresh, stale_s=1.2
            )

            # è¼‰å…¥æ¨¡å‹
            model_path = ensure_model(model_name)
            options = mp_vision.PoseLandmarkerOptions(
                base_options=BaseOptions(model_asset_path=model_path),
                running_mode=mp_vision.RunningMode.VIDEO,
                num_poses=6,
                min_pose_detection_confidence=0.5,
                min_pose_presence_confidence=0.5,
                min_tracking_confidence=0.5,
                output_segmentation_masks=False,
            )
            self.landmarker = mp_vision.PoseLandmarker.create_from_options(options)

            self.is_monitoring = True

            # é–‹å§‹ç›£æ§ç·šç¨‹
            thread = threading.Thread(target=self._monitoring_loop)
            thread.daemon = True
            thread.start()

            return True
        except Exception as e:
            print(f"å•Ÿå‹•ç›£æ§å¤±æ•—: {e}")
            return False

    def _monitoring_loop(self):
        """ç›£æ§ä¸»å¾ªç’°"""
        frame_idx = 0
        start_time = time.time()

        while self.is_monitoring and self.cap and self.cap.isOpened():
            try:
                ok, frame = self.cap.read()
                if not ok:
                    break

                current_time = time.time()
                ts_s = current_time - start_time

                # è™•ç†å¹€
                annotated, fall_detected, person_count = self.process_frame(frame, ts_s)

                # ç·¨ç¢¼ç‚ºJPEGä¸¦ç™¼é€åˆ°å‰ç«¯
                _, buffer = cv2.imencode(".jpg", annotated)
                frame_data = base64.b64encode(buffer).decode("utf-8")

                # é€šéWebSocketç™¼é€
                socketio.emit(
                    "video_frame",
                    {
                        "image": frame_data,
                        "timestamp": datetime.now().isoformat(),
                        "person_count": person_count,
                        "fall_detected": fall_detected,
                    },
                )

                frame_idx += 1
                time.sleep(0.03)  # ç´„30 FPS

            except Exception as e:
                print(f"ç›£æ§å¾ªç’°éŒ¯èª¤: {e}")
                break

        self.stop_monitoring()

    def stop_monitoring(self):
        """åœæ­¢ç›£æ§"""
        self.is_monitoring = False
        if self.cap:
            self.cap.release()
            self.cap = None
        if self.landmarker:
            self.landmarker.close()
            self.landmarker = None
        self.tracker = None


# å…¨åŸŸæ‡‰ç”¨å¯¦ä¾‹
fall_app = FallDetectionApp()


# è·¯ç”±
@app.route("/")
def index():
    return render_template("index.html")


@app.route("/api/start", methods=["POST"])
def start_monitoring():
    data = request.json
    source = data.get("source", "0")
    model = data.get("model", "heavy")

    success = fall_app.start_monitoring(source, model)
    return jsonify({"success": success})


@app.route("/api/stop", methods=["POST"])
def stop_monitoring():
    fall_app.stop_monitoring()
    return jsonify({"success": True})


@app.route("/api/status")
def get_status():
    return jsonify(
        {
            "is_monitoring": fall_app.is_monitoring,
            "telegram_configured": bool(TELEGRAM_BOT_TOKEN != "YOUR_BOT_TOKEN_HERE"),
        }
    )


@app.route("/api/settings", methods=["POST"])
def update_settings():
    data = request.json

    # æ›´æ–°åƒæ•¸
    if "fall_vdrop" in data:
        fall_app.params.fall_vdrop = float(data["fall_vdrop"])
    if "fall_angle_deg" in data:
        fall_app.params.fall_angle_deg = float(data["fall_angle_deg"])
    if "fall_aspect" in data:
        fall_app.params.fall_aspect = float(data["fall_aspect"])
    if "fall_dwell_s" in data:
        fall_app.params.fall_dwell_s = float(data["fall_dwell_s"])

    return jsonify({"success": True})


@socketio.on("connect")
def handle_connect():
    print("å®¢æˆ¶ç«¯å·²é€£æ¥")
    emit("connected", {"data": "é€£æ¥æˆåŠŸ"})


@socketio.on("disconnect")
def handle_disconnect():
    print("å®¢æˆ¶ç«¯å·²æ–·é–‹")


if __name__ == "__main__":
    socketio.run(app, host="0.0.0.0", port=5000, debug=True)
